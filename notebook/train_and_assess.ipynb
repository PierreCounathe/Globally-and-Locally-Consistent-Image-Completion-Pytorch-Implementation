{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on CPU\n",
      "running on CPU\n",
      "running on CPU\n"
     ]
    }
   ],
   "source": [
    "# Imports and check for GPU availability\n",
    "import torch\n",
    "from torch import *\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from torchvision import datasets\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import random as r\n",
    "import cv2\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda')\n",
    "  use_cuda = True\n",
    "  print('running on GPU')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "  use_cuda = False\n",
    "  print('running on CPU')\n",
    "\n",
    "# Import models classes, training algorithms and utils functions\n",
    "from models import *\n",
    "from trainers import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.RandomResizedCrop((256,256), scale = (0.6666666666667,1.0) ,ratio=(1.0,1.0)), transforms.ToTensor()])\n",
    "train_set = torchvision.datasets.ImageFolder(root='data/celeba_train', transform= transform)\n",
    "test_set = torchvision.datasets.ImageFolder(root=\"./data/celeba_test\", transform=transform)\n",
    "dataset_with_labels = True\n",
    "test_loader = torch.utils.data.DataLoader(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train_set = torchvision.datasets.ImageFolder(root = \"data/train_set\", transform = transform) #200K images -1 allant de 1 à 199999\n",
    "test_set = torchvision.datasets.ImageFolder(root = \"data/test_set\", transform = transform) #2600 images #A modifier pour prendre les images de 200000 à 202599\n",
    "dataset_with_labels = True\n",
    "test_loader = torch.utils.data.DataLoader(test_set)\n",
    "number_of_figures_saved = 142\n",
    "\n",
    "fun_set = torchvision.datasets.ImageFolder(root = \"data/fun_set\", transform = transform)\n",
    "fun_loader = torch.utils.data.DataLoader(fun_set)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 4e-4\n",
    "lr_d = 1.\n",
    "lr_c = 1.\n",
    "try:\n",
    "    model_c = Completion().cuda()\n",
    "    model_d = Discriminator().cuda()\n",
    "except:\n",
    "    model_c = Completion()\n",
    "    model_d = Discriminator()\n",
    "opt_d = torch.optim.Adadelta(model_d.parameters(), lr = lr_d) \n",
    "opt_c = torch.optim.Adadelta(model_c.parameters(), lr = lr_c)\n",
    "number_of_figures_saved = 0 \n",
    "pixel = (130,107,95) # This is the mean value of all pixels in our training data_set on Celeb-A !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8\n",
    "#load_checkpoint(model_c,opt_c,\"model_c_save/model_c_checkpoint_c_and_d_training_epoch{}.pth.tar\".format(n))\n",
    "#load_checkpoint(model_d,opt_d,\"model_d_save/model_d_checkpoint_c_and_d_training_epoch{}.pth.tar\".format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning the training the Completion Network\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c41837e435cc40f5aec18fdacd0bcc39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9866b1f8d97451695cb03b0f73034d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_C(model_c, batch_size = 16 , train_acc_period = 50, n_epoch = 5, num_samples = 8000, save_period = 5, use_cuda = use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_D(model_d, model_c, train_acc_period = 50, batch_size = 16, num_samples= 8000, save_period = 2, n_epoch = 5, use_cuda = use_cuda) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_C_and_D(model_c, model_d, alpha, n_epoch=10, train_acc_period = 50, batch_size = 16, num_samples = 8000, save_period = 5, use_cuda = use_cuda)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "99164430ff28c315eb5bd77abf76a69247befbbf138451ec07a913c7305a0273"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
